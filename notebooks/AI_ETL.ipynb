{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b605c911-2493-4fcc-9aa9-af0df26cadf1",
      "metadata": {
        "id": "b605c911-2493-4fcc-9aa9-af0df26cadf1"
      },
      "source": [
        "# AI Engineering: Data ETL Pipeline with LLMs\n",
        "\n",
        "### 1. Project Objective (Business Context)\n",
        "\n",
        "The objective of this project is to simulate an order from a pharmaceutical company: to extract variables of interest dynamically from a corpus of unstructured documents (PDFs of *papers* pharmaceuticals).\n",
        "\n",
        "The final deliverable is a single `.csv` table where each row represents a document and each column an extracted interest variable. If a document does not contain a variable, a null value (`null`) must be imputed.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Technical Challenge and Engineering Solution\n",
        "\n",
        "Performing this task in an environment with limited resources (such as Google Colab T4) presents three major AI engineering challenges:\n",
        "\n",
        "1. **Memory (OOM):** Powerful LLMs (7B+ params) do not fit in GPUs of <16GB VRAM.\n",
        "\n",
        "2. **Efficiency (Latency):** Processing N documents sequentially (one by one) is extremely slow.\n",
        "\n",
        "3. **Reliability (Parsing):** LLMs are \"locuate\" and rarely return perfect JSON, which causes parsing failures.\n",
        "\n",
        "This notebook implements an **optimized AI pipeline** to solve these problems:\n",
        "\n",
        "* **Model:** `mistralai/Mistral-7B-Instruct-v0.3` (a high-performance 7B model).\n",
        "\n",
        "* **Memory Optimization:** **4-bit (NF4)** quantization is used with `bitsandbytes` to load the 7B model on ~5GB of VRAM, avoiding OOM errors.\n",
        "\n",
        "* **Batching:** The code was refactored to go from N sequential calls to only **2 calls to the GPU** (one to discover variables and another to extract data), multiplying efficiency.\n",
        "\n",
        "* **Robust Parsing:** A `robust_json_parser` was implemented that \"hunts\" the JSON block within the LLM response, ignoring the extra text to avoid failures.\n",
        "\n",
        "* **Data Cleaning:** `difflib` is used to find and merge columns with similar names (e.g. \"placebo effect\" and \"placebo_effect\") dynamically generated by AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "k4om4EGBanpj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4om4EGBanpj",
        "outputId": "88432f3f-8f39-469d-e117-3ac1df6c0630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m Skipping \u001b[1mbitsandbytes\u001b[0m as it is not installed\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m Skipping \u001b[1mpdfplumber\u001b[0m as it is not installed\n",
            "\u001b[2mUninstalled \u001b[1m5 packages\u001b[0m \u001b[2min 957ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.11.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.8.0+cu126\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.8.0+cu126\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.23.0+cu126\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m27 packages\u001b[0m \u001b[2min 1.31s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m15 packages\u001b[0m \u001b[2min 49.08s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m12 packages\u001b[0m \u001b[2min 45ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m15 packages\u001b[0m \u001b[2min 209ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.1.3.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.0.2.54\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.2.106\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.4.5.107\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.1.0.106\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.20.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.1.105\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.4.1+cu121\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.4.1+cu121\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.19.1+cu121\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m48 packages\u001b[0m \u001b[2min 351ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m6 packages\u001b[0m \u001b[2min 1.39s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m6 packages\u001b[0m \u001b[2min 57ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.48.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpdfminer-six\u001b[0m\u001b[2m==20251107\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpdfplumber\u001b[0m\u001b[2m==0.11.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpypdfium2\u001b[0m\u001b[2m==5.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip uninstall torch torchvision torchaudio transformers bitsandbytes accelerate pdfplumber\n",
        "!uv pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!uv pip install transformers bitsandbytes accelerate pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9J-G6m0uZ8Fs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J-G6m0uZ8Fs",
        "outputId": "22f62477-73b5-4ab8-c862-d90478cc6ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1+cu121\n",
            "True\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "!nvcc --version  # Para confirmar CUDA del sistema (~12.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e90a8686",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e90a8686",
        "outputId": "75195ea6-7a02-4582-c62a-6308023ed212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'R10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'R55' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'R10' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'R40' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'R37' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated txt files: 6\n"
          ]
        }
      ],
      "source": [
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import multiprocessing\n",
        "import pdfplumber, os\n",
        "import warnings\n",
        "\n",
        "# Suppress pdfminer warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='pdfminer')\n",
        "\n",
        "def pdf_to_text_worker(pdf_path: str,processed_dir:str) -> str:\n",
        "    \"\"\"\n",
        "    Worker function to extract text from a single PDF.\n",
        "    Saves the .txt file to the specified 'processed_dir'.\n",
        "    \"\"\"\n",
        "    # Generate txt path\n",
        "    file_name = os.path.basename(pdf_path)\n",
        "    txt_name = file_name.replace('.pdf', '.txt')\n",
        "    text_path = os.path.join(processed_dir, txt_name)\n",
        "    parts = []\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                t = page.extract_text()\n",
        "                if t:\n",
        "                    parts.append(t)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: failed to process {pdf_path}: {e}\")\n",
        "    \n",
        "    # Save extracted text\n",
        "    with open(text_path, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(parts))\n",
        "    return text_path\n",
        "\n",
        "# path to raw data\n",
        "data_raw_path = \"../data/raw/\"\n",
        "data_processed_path = \"../data/processed/\"\n",
        "\n",
        "# Ensure processed directory exists\n",
        "os.makedirs(data_processed_path, exist_ok=True)\n",
        "\n",
        "# check if directory exists\n",
        "if not os.path.isdir(data_raw_path):\n",
        "    print(f\"Error: Directory not found at {data_raw_path}\")\n",
        "    print(\"Please create 'data/raw' and add your PDFs.\")\n",
        "    pdf_paths = []\n",
        "else:\n",
        "    pdf_paths = [os.path.join(data_raw_path, f) for f in os.listdir(data_raw_path) if f.lower().endswith('.pdf')]\n",
        "\n",
        "# Set workers based on CPU count\n",
        "max_workers = max(1, min(4, multiprocessing.cpu_count()-1))\n",
        "\n",
        "txt_paths = []\n",
        "if pdf_paths:\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
        "        # Submit tasks\n",
        "        futures = {ex.submit(pdf_to_text_worker, p, data_processed_path): p for p in pdf_paths}\n",
        "        for fut in as_completed(futures):\n",
        "            try:\n",
        "                txt_paths.append(fut.result())\n",
        "            except Exception as e:\n",
        "                print(\"pdf->txt failed:\", e)\n",
        "\n",
        "    print(f\"Generated {len(txt_paths)} text files from {len(pdf_paths)} PDFs: {txt_paths}\")\n",
        "    for p in txt_paths:\n",
        "        print(f\" - Generated: {p}\")\n",
        "else:\n",
        "    print(\"No PDFs found in 'data/raw/' to process.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c26fd794",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9e59ce541fc24e2d94270097128e47bb",
            "0e95af62a36940c8a998899b52aba8a7",
            "cbecfc9d58c74fdaab62d0ac431ea4b6",
            "8b88a01f48924d7393438e0c3129089e",
            "ee05eb469df842a780f0e602e5e482e8",
            "59deaf6c098246b3be03000f451b5139",
            "9e4013685e55413ca8ee4c6fef4b2fc0",
            "90495963d3b740058e315fb78b35439c",
            "9e9851c3d80e4169a6260e44afaf2706",
            "93102a3e79234c278464ac6687b05727",
            "b80a058c41c242f0b5d5076c97114870"
          ]
        },
        "id": "c26fd794",
        "outputId": "a3e5fb0c-11f5-4e1d-d6c8-37a47f9517c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e59ce541fc24e2d94270097128e47bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Efficient Batch Extraction ---\n",
            "Processed text files (n): 6\n",
            " - fpsyg-12-639236.txt\n",
            " - fpsyt-14-1301143.txt\n",
            " - fpubh-10-1045777.txt\n",
            " - fpsyg-11-01354.txt\n",
            " - fpsyg-08-00308.txt\n",
            " - fpsyg-09-01240.txt\n",
            "Preparing variable extraction batch for 6 documents...\n",
            "  -> Generating batch of 6 prompts (batch_size=4)...\n",
            "  -> Batch generation complete.\n",
            "Vars raw for doc 0: {\"variables\": [\"Placebo cream\", \"Experiment type (within-subjects and mixed design)\", \"Placebo effec...\n",
            "Parsed vars for doc 0: ['Placebo cream', 'Experiment type (within-subjects and mixed design)', 'Placebo effect on pain and stress, moderated by participant and experimenter sex']\n",
            "Vars raw for doc 1: {\"variables\": [\"Placebo\", \"Neuroplasticity Placebo Theory\", \"Depression\", \"Fronto-limbic areas\", \"Pl...\n",
            "Parsed vars for doc 1: ['Placebo', 'Neuroplasticity Placebo Theory', 'Depression', 'Fronto-limbic areas', 'Placebo response in antidepressant trials']\n",
            "Vars raw for doc 2: {\"variables\": [\"depression\", \"cognitive distortion detection\", \"multi-task learning model\", \"pre-tra...\n",
            "Parsed vars for doc 2: ['depression', 'cognitive distortion detection', 'multi-task learning model', 'pre-trained model', 'user representations']\n",
            "Vars raw for doc 3: {\"variables\": [\"Placebo Effects\", \"Artifacts (physical environmental factors)\", \"Placebo Studies\"]}...\n",
            "Parsed vars for doc 3: ['Placebo Effects', 'Artifacts (physical environmental factors)', 'Placebo Studies']\n",
            "Vars raw for doc 4: {\"variables\": [\"Contact Heat Thermal Stimulation\", \"Conditioning Paradigm\", \"Placebo Hypoalgesia\", \"...\n",
            "Parsed vars for doc 4: ['Contact Heat Thermal Stimulation', 'Conditioning Paradigm', 'Placebo Hypoalgesia', 'Nocebo Hyperalgesia', 'Anxiety Severity', 'Anxiety Sensitivity', 'Physiological Suggestibility', 'Motivation (Value/Utility and Pressure/Tense subscales)', 'Depression']\n",
            "Vars raw for doc 5: {\"variables\": [\"Bayes' Theorem\", \"Depression Tests (Zung's Self-Rating Depression Scale, Hamilton Ra...\n",
            "Parsed vars for doc 5: [\"Bayes' Theorem\", \"Depression Tests (Zung's Self-Rating Depression Scale, Hamilton Rating Scale for Depression, Center for Epidemiological Studies for Depression, Beck Depression Inventory, Teate Depression Inventory)\", 'Diagnostic Accuracy']\n",
            "Extracted unique variables: ['Nocebo hyperalgesia', 'Contact heat thermal stimulation', 'Depression', 'Placebo response in antidepressant trials', 'User representations', 'Neuroplasticity placebo theory', 'Placebo', 'Fronto-limbic areas', 'Diagnostic accuracy', 'Artifacts (physical environmental factors)', 'Placebo hypoalgesia', 'Placebo effects', \"Depression tests (zung's self-rating depression scale, hamilton rating scale for depression, center for epidemiological studies for depression, beck depression inventory, teate depression inventory)\", 'Placebo studies', \"Bayes' theorem\", 'Cognitive distortion detection', 'Experiment type (within-subjects and mixed design)', 'Placebo effect on pain and stress, moderated by participant and experimenter sex', 'Physiological suggestibility', 'Multi-task learning model', 'Pre-trained model', 'Anxiety severity', 'Conditioning paradigm', 'Anxiety sensitivity', 'Motivation (value/utility and pressure/tense subscales)', 'Placebo cream']\n",
            "Preparing data extraction batch for 6 documents...\n",
            "  -> Generating batch of 6 prompts (batch_size=2)...\n",
            "  -> Batch generation complete.\n",
            "Raw output for fpsyg-12-639236.txt: {\n",
            "  \"document\": \"fpsyg-12-639236.txt\",\n",
            "  \"Placebo\": \"observed effect\",\n",
            "  \"Pain\": \"no placebo effect\"...\n",
            "Raw output for fpsyt-14-1301143.txt: {\n",
            "  \"document\": \"fpsyt-14-1301143.txt\",\n",
            "  \"Neuroplasticity Placebo Theory\": \"yes\",\n",
            "  \"Placebo\": \"des...\n",
            "Raw output for fpubh-10-1045777.txt: {\n",
            "  \"document\": \"fpubh-10-1045777.txt\",\n",
            "  \"Cognitive distortion based depression detection and analy...\n",
            "Raw output for fpsyg-11-01354.txt: {\n",
            "  \"document\": \"fpsyg-11-01354.txt\",\n",
            "  \"Placebo\": \"observed effect\",\n",
            "  \"Nocebo hyperalgesia\": \"null...\n",
            "Raw output for fpsyg-08-00308.txt: {\n",
            "  \"document\": \"ORIGINALRESEARCH\",\n",
            "  \"doi\": \"10.3389/fpsyg.2017.00308\",\n",
            "  \"Placebo\": \"hypoalgesia\",...\n",
            "Raw output for fpsyg-09-01240.txt: {\n",
            "  \"document\": \"fpsyg-09-01240.txt\",\n",
            "  \"Bayes' theorem\": \"used\",\n",
            "  \"diagnostic accuracy\": \"analyzed...\n",
            "Sanitizing and merging results...\n",
            "\n",
            "--- Process Complete ---\n",
            "DataFrame saved to 'dynamic_table_final.csv'  |  shape: (6, 58)\n",
            "Time : 561.3332738876343 s\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d8d5fd52-ff1b-4f68-add1-059021b84d56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>placebo</th>\n",
              "      <th>pain</th>\n",
              "      <th>stress</th>\n",
              "      <th>participant sex</th>\n",
              "      <th>experimenter sex</th>\n",
              "      <th>depression</th>\n",
              "      <th>depression tests</th>\n",
              "      <th>neuroplasticity placebo theory</th>\n",
              "      <th>nocebo hyperalgesia</th>\n",
              "      <th>...</th>\n",
              "      <th>barlow 2015</th>\n",
              "      <th>layard 2013</th>\n",
              "      <th>black et al 1999</th>\n",
              "      <th>black and craig 2002</th>\n",
              "      <th>barlow et al 2013</th>\n",
              "      <th>lesaffre et al 2007</th>\n",
              "      <th>begg 1987</th>\n",
              "      <th>hui and zhou 1998</th>\n",
              "      <th>zhou 1998</th>\n",
              "      <th>van stralen et al 2009</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fpsyg-12-639236.txt</td>\n",
              "      <td>observed effect</td>\n",
              "      <td>no placebo effect</td>\n",
              "      <td>placebo effect</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fpsyt-14-1301143.txt</td>\n",
              "      <td>designed to be inert in randomized controlled ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>disorder that has the highest placebo response...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fpubh-10-1045777.txt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fpsyg-11-01354.txt</td>\n",
              "      <td>observed effect</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>symptoms reduction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ORIGINALRESEARCH</td>\n",
              "      <td>hypoalgesia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>fpsyg-09-01240.txt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>cited</td>\n",
              "      <td>cited</td>\n",
              "      <td>cited</td>\n",
              "      <td>cited</td>\n",
              "      <td>cited</td>\n",
              "      <td>cited</td>\n",
              "      <td>cited</td>\n",
              "      <td>cited</td>\n",
              "      <td>cited</td>\n",
              "      <td>cited</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows Ã— 58 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8d5fd52-ff1b-4f68-add1-059021b84d56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8d5fd52-ff1b-4f68-add1-059021b84d56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8d5fd52-ff1b-4f68-add1-059021b84d56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1cccd773-6281-4b29-8acf-573394dd2d82\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1cccd773-6281-4b29-8acf-573394dd2d82')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1cccd773-6281-4b29-8acf-573394dd2d82 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6e882916-4710-41d9-9fa8-d51f58008d16\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6e882916-4710-41d9-9fa8-d51f58008d16 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               document                                            placebo  \\\n",
              "0   fpsyg-12-639236.txt                                    observed effect   \n",
              "1  fpsyt-14-1301143.txt  designed to be inert in randomized controlled ...   \n",
              "2  fpubh-10-1045777.txt                                                NaN   \n",
              "3    fpsyg-11-01354.txt                                    observed effect   \n",
              "4      ORIGINALRESEARCH                                        hypoalgesia   \n",
              "5    fpsyg-09-01240.txt                                                NaN   \n",
              "\n",
              "                pain          stress  participant sex  experimenter sex  \\\n",
              "0  no placebo effect  placebo effect              NaN               NaN   \n",
              "1                NaN             NaN              NaN               NaN   \n",
              "2                NaN             NaN              NaN               NaN   \n",
              "3                NaN             NaN              NaN               NaN   \n",
              "4                NaN             NaN              NaN               NaN   \n",
              "5                NaN             NaN              NaN               NaN   \n",
              "\n",
              "                                          depression  depression tests  \\\n",
              "0                                                NaN               NaN   \n",
              "1  disorder that has the highest placebo response...               NaN   \n",
              "2                                                NaN               NaN   \n",
              "3                                 symptoms reduction               NaN   \n",
              "4                                                NaN               NaN   \n",
              "5                                                NaN               NaN   \n",
              "\n",
              "   neuroplasticity placebo theory  nocebo hyperalgesia  ... barlow 2015  \\\n",
              "0                             NaN                  NaN  ...         NaN   \n",
              "1                             NaN                  NaN  ...         NaN   \n",
              "2                             NaN                  NaN  ...         NaN   \n",
              "3                             NaN                  NaN  ...         NaN   \n",
              "4                             NaN                  NaN  ...         NaN   \n",
              "5                             NaN                  NaN  ...       cited   \n",
              "\n",
              "  layard 2013  black et al 1999 black and craig 2002 barlow et al 2013  \\\n",
              "0         NaN               NaN                  NaN               NaN   \n",
              "1         NaN               NaN                  NaN               NaN   \n",
              "2         NaN               NaN                  NaN               NaN   \n",
              "3         NaN               NaN                  NaN               NaN   \n",
              "4         NaN               NaN                  NaN               NaN   \n",
              "5       cited             cited                cited             cited   \n",
              "\n",
              "  lesaffre et al 2007 begg 1987  hui and zhou 1998 zhou 1998  \\\n",
              "0                 NaN       NaN                NaN       NaN   \n",
              "1                 NaN       NaN                NaN       NaN   \n",
              "2                 NaN       NaN                NaN       NaN   \n",
              "3                 NaN       NaN                NaN       NaN   \n",
              "4                 NaN       NaN                NaN       NaN   \n",
              "5               cited     cited              cited     cited   \n",
              "\n",
              "  van stralen et al 2009  \n",
              "0                    NaN  \n",
              "1                    NaN  \n",
              "2                    NaN  \n",
              "3                    NaN  \n",
              "4                    NaN  \n",
              "5                  cited  \n",
              "\n",
              "[6 rows x 58 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import pdfplumber\n",
        "import warnings\n",
        "import torch\n",
        "import gc, re, json, difflib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# --- 1. Model Configuration & Loading ---\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "device_has_cuda = torch.cuda.is_available()\n",
        "print(f\"CUDA available: {device_has_cuda}\")\n",
        "\n",
        "quantization_config = None\n",
        "if device_has_cuda:\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "    )\n",
        "    model_dtype = torch.float16\n",
        "else:\n",
        "    model_dtype = torch.float32\n",
        "    print(\"Running on CPU: Expect significantly slower inference.\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\" if device_has_cuda else None,\n",
        "    torch_dtype=model_dtype,\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "gc.collect()\n",
        "if device_has_cuda:\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "device_id = 0 if device_has_cuda else -1\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device_id\n",
        ")\n",
        "\n",
        "# --- 2. Efficient Batch Generation ---\n",
        "\n",
        "def generate_batch(prompts: list[str], max_new_tokens: int = 300, temperature: float = 0.05, batch_size: int = 4):\n",
        "    \"\"\"\n",
        "    Processes a list of prompts in parallel batches for maximum GPU efficiency.\n",
        "    \"\"\"\n",
        "    print(f\"  -> Generating batch of {len(prompts)} prompts (batch_size={batch_size})...\")\n",
        "    messages_list = [[{\"role\": \"user\", \"content\": p}] for p in prompts]\n",
        "    formatted_prompts = [tokenizer.apply_chat_template(\n",
        "        m, tokenize=False, add_generation_prompt=True\n",
        "    ) for m in messages_list]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = generator(\n",
        "            formatted_prompts,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=(temperature > 0),\n",
        "            temperature=temperature,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            return_full_text=False,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "\n",
        "    gc.collect()\n",
        "    if device_has_cuda:\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if not outputs or not isinstance(outputs, list) or not isinstance(outputs[0], list):\n",
        "         print(f\"Warning: Pipeline output format unexpected. Output: {str(outputs)[:200]}...\")\n",
        "         if isinstance(outputs, list) and len(outputs) > 0 and 'generated_text' in outputs[0]:\n",
        "             return [out['generated_text'].strip() for out in outputs]\n",
        "         return [\"ERROR_PARSING_BATCH\"] * len(prompts)\n",
        "\n",
        "    results = [out[0]['generated_text'].strip() for out in outputs]\n",
        "    print(f\"  -> Batch generation complete.\")\n",
        "    return results\n",
        "\n",
        "# --- 3. Robust JSON Parsing ---\n",
        "\n",
        "def robust_json_parser(text: str) -> dict | list | None:\n",
        "    \"\"\"\n",
        "    Extracts the first valid JSON block from an LLM's potentially \"chatty\" output.\n",
        "    \"\"\"\n",
        "    import json, re\n",
        "    try:\n",
        "        m = re.search(r'```json\\s*(\\{.*?\\}|\\[.*?\\])\\s*```', text, re.DOTALL)\n",
        "        if m:\n",
        "            return json.loads(m.group(1))\n",
        "        \n",
        "        start_obj = text.find('{')\n",
        "        start_arr = text.find('[')\n",
        "        starts = [(start_obj, '{'), (start_arr, '[')]\n",
        "        starts = [s for s in starts if s[0] != -1]\n",
        "        if not starts:\n",
        "            return None\n",
        "        starts.sort()\n",
        "        start, ch = starts[0]\n",
        "        if ch == '{':\n",
        "            end = text.rfind('}')\n",
        "        else:\n",
        "            end = text.rfind(']')\n",
        "        if start != -1 and end != -1 and end > start:\n",
        "            candidate = text[start:end+1]\n",
        "            return json.loads(candidate)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"  -> Robust parser failed: {e}. Text: {text[:100]}...\")\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def parse_variables_json(text: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Takes raw LLM text, parses the JSON, and extracts a clean list of variable names.\n",
        "    \"\"\"\n",
        "    parsed_data = robust_json_parser(text)\n",
        "\n",
        "    if isinstance(parsed_data, dict) and \"variables\" in parsed_data:\n",
        "        var_list = parsed_data[\"variables\"]\n",
        "        normalized_vars = []\n",
        "        for item in var_list:\n",
        "            if isinstance(item, str):\n",
        "                normalized_vars.append(item)\n",
        "            elif isinstance(item, dict):\n",
        "                if 'name' in item:\n",
        "                    normalized_vars.append(item['name'])\n",
        "                elif 'variable_name' in item:\n",
        "                    normalized_vars.append(item['variable_name'])\n",
        "                else:\n",
        "                    normalized_vars.append(list(item.keys())[0] if item else \"unknown_var\")\n",
        "            else:\n",
        "                normalized_vars.append(str(item))\n",
        "        if all(v == 'name' for v in normalized_vars):\n",
        "            return ['drugs', 'methods', 'results']\n",
        "        return normalized_vars\n",
        "\n",
        "    print(\"Parsing variables failed; using default.\")\n",
        "    return [\"drug_name\", \"experiment_type\", \"observed_results\"]\n",
        "\n",
        "def parse_doc_json(text: str, doc_name: str, variables: list[str]) -> dict:\n",
        "    \"\"\"\n",
        "    Takes raw LLM text for data extraction and builds a robust dictionary.\n",
        "    (Includes fix to always use the correct doc_name).\n",
        "    \"\"\"\n",
        "    # ALWAYS start with the *correct* document name.\n",
        "    result = {\"document\": os.path.basename(doc_name)}\n",
        "    \n",
        "    parsed = robust_json_parser(text)\n",
        "\n",
        "    if isinstance(parsed, dict):\n",
        "        for k, v in parsed.items():\n",
        "            key = str(k).strip()\n",
        "            # Ignore the 'document' key from the LLM; we already set the correct one.\n",
        "            if key.lower() == \"document\":\n",
        "                continue \n",
        "            result[key] = v if v is not None else None\n",
        "            \n",
        "    elif isinstance(parsed, list):\n",
        "        merged = {}\n",
        "        for item in parsed:\n",
        "            if isinstance(item, dict):\n",
        "                merged.update(item)\n",
        "        for k, v in merged.items():\n",
        "            if str(k).strip().lower() != \"document\": # Also apply the fix here\n",
        "                result[str(k).strip()] = v if v is not None else None\n",
        "\n",
        "    # Schema enforcement\n",
        "    for var in variables:\n",
        "        if var not in result:\n",
        "            result[var] = None\n",
        "    return result\n",
        "\n",
        "json_example_str = '{\"variables\": [\"drug_name\", \"experiment_type\", \"observed_results\"]}'\n",
        "\n",
        "# --- 4. Batch Extraction Logic ---\n",
        "\n",
        "def extract_variables_batch(txt_paths: list[str]) -> list[str]:\n",
        "    \"\"\"\n",
        "    Builds and executes a batch job to discover all unique variables from all docs.\n",
        "    \"\"\"\n",
        "    if not txt_paths:\n",
        "        return [\"drug_name\", \"experiment_type\", \"observed_results\"]\n",
        "\n",
        "    prompts = []\n",
        "    print(f\"Preparing variable extraction batch for {len(txt_paths)} documents...\")\n",
        "    for p in txt_paths:\n",
        "        try:\n",
        "            with open(p, 'r', encoding='utf-8') as f:\n",
        "                t = f.read()\n",
        "            truncated_text = t[:8000]\n",
        "            prompt = f\"\"\"\n",
        "            Analyze the following text from a pharmaceutical paper. Identify 3-5 key variables (like drugs, placebos, methods, or results).\n",
        "            Respond ONLY with a valid JSON object in the format: {json_example_str}.\n",
        "            Do not add explanations or chat.\n",
        "\n",
        "            Text:\n",
        "            {truncated_text}\n",
        "            \"\"\"\n",
        "            prompts.append(prompt)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Warning: File not found at {p}. Skipping.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Failed to read {p}: {e}. Skipping.\")\n",
        "\n",
        "\n",
        "    if not prompts:\n",
        "        print(\"No valid text files found to process.\")\n",
        "        return [\"drug_name\", \"experiment_type\", \"observed_results\"]\n",
        "\n",
        "    raw_outputs = generate_batch(prompts, max_new_tokens=200, temperature=0.05, batch_size=4)\n",
        "\n",
        "    variables_per_doc = []\n",
        "    for i, raw_text in enumerate(raw_outputs):\n",
        "        print(f\"Vars raw for doc {i}: {raw_text[:100]}...\")\n",
        "        vars_per_doc_list = parse_variables_json(raw_text)\n",
        "        print(f\"Parsed vars for doc {i}: {vars_per_doc_list}\")\n",
        "        variables_per_doc.append(set(vars_per_doc_list))\n",
        "\n",
        "    all_vars = list(set().union(*variables_per_doc))\n",
        "    all_vars = [v.lower().strip() for v in all_vars]\n",
        "    all_vars = list(set(all_vars))\n",
        "    all_vars = [v.capitalize() for v in all_vars]\n",
        "    \n",
        "    print(f\"Extracted unique variables: {all_vars}\")\n",
        "    return all_vars or [\"drug_name\", \"experiment_type\", \"observed_results\"]\n",
        "\n",
        "def extract_data_batch(txt_paths: list[str], variables: list[str]) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Builds and executes a batch job to extract the structured data for all docs.\n",
        "    \"\"\"\n",
        "    prompts = []\n",
        "    doc_names = []\n",
        "    print(f\"Preparing data extraction batch for {len(txt_paths)} documents...\")\n",
        "    \n",
        "    for p in txt_paths:\n",
        "        try:\n",
        "            with open(p, 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "            doc_names.append(os.path.basename(p)) # Add doc_name only if read is successful\n",
        "            truncated_text = text[:8000]\n",
        "\n",
        "            example_json_structure = {\"document\": os.path.basename(p)}\n",
        "            for var in variables:\n",
        "                example_json_structure[var] = \"null\"\n",
        "            json_format_instruction = json.dumps(example_json_structure, ensure_ascii=False, indent=2)\n",
        "\n",
        "            few_shot = '{\"document\": \"example.txt\", \"placebo\": \"observed effect\", \"depression\": \"symptoms reduction\"}'\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            You are an expert pharma data extractor. Read the text and extract all relevant info.\n",
        "            Respond ONLY with a valid JSON object. Do not add explanations.\n",
        "            Use \"null\" if data is absent. Do not duplicate keys.\n",
        "\n",
        "            Example format: {json_format_instruction}\n",
        "            Example data: {few_shot}\n",
        "\n",
        "            Text to analyze:\n",
        "            {truncated_text}\n",
        "            \"\"\"\n",
        "            prompts.append(prompt)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Warning: File not found at {p}. Skipping data extraction.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Failed to read {p}: {e}. Skipping data extraction.\")\n",
        "\n",
        "    if not prompts:\n",
        "        print(\"No valid text files found for data extraction.\")\n",
        "        return []\n",
        "\n",
        "    raw_outputs = generate_batch(prompts, max_new_tokens=500, temperature=0.05, batch_size=2)\n",
        "\n",
        "    results = []\n",
        "    for doc_name, raw_text in zip(doc_names, raw_outputs):\n",
        "        print(f\"Raw output for {doc_name}: {raw_text[:100]}...\")\n",
        "        result = parse_doc_json(raw_text, doc_name, variables)\n",
        "        results.append(result)\n",
        "    \n",
        "    return results\n",
        "\n",
        "# --- 5. Post-Processing & DataFrame Creation ---\n",
        "\n",
        "def normalize_key(k: str) -> str:\n",
        "    \"\"\"A simple normalization function to clean column names.\"\"\"\n",
        "    if k is None:\n",
        "        return \"unknown\"\n",
        "    k = str(k).strip()\n",
        "    k = k.replace(\"â€™\", \"'\").replace(\"â€“\", \"-\")\n",
        "    k = re.sub(r\"[^\\w\\s]\", \" \", k)\n",
        "    k = re.sub(r\"\\s+\", \" \", k).strip().lower()\n",
        "    return k\n",
        "\n",
        "def normalize_value(v):\n",
        "    \"\"\"Cleans up values, converting \"null\" strings to None and serializing JSON.\"\"\"\n",
        "    if v is None:\n",
        "        return None\n",
        "    if isinstance(v, str):\n",
        "        vv = v.strip()\n",
        "        if vv.lower() in (\"null\", \"none\", \"\", \"n/a\"):\n",
        "            return None\n",
        "        return vv\n",
        "    try:\n",
        "        return json.dumps(v, ensure_ascii=False)\n",
        "    except Exception:\n",
        "        return str(v)\n",
        "\n",
        "# --- 6. Execution ---\n",
        "gc.collect()\n",
        "if device_has_cuda:\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "if 'txt_paths' not in globals() or not txt_paths:\n",
        "    print(\"Error: `txt_paths` is not defined. Run the PDF-to-text cell (Cell 3) first.\")\n",
        "else:\n",
        "    print(\"--- Starting Efficient Batch Extraction ---\")\n",
        "    print(\"Processed text files (n):\", len(txt_paths))\n",
        "    for p in txt_paths:\n",
        "        print(\" -\", p) # Show txt paths\n",
        "\n",
        "    # Step 1: Discover all unique columns from all docs in one batch\n",
        "    variables = extract_variables_batch(txt_paths)\n",
        "    \n",
        "    # Step 2: \"Fill in the table\" for all docs in a second batch\n",
        "    results = extract_data_batch(txt_paths, variables)\n",
        "\n",
        "    # Step 3: Sanitize, normalize, and merge results\n",
        "    print(\"Sanitizing and merging results...\")\n",
        "    sanitized_results = []\n",
        "    for r in results:\n",
        "        nr = {}\n",
        "        for k, v in r.items():\n",
        "            nk = normalize_key(k)\n",
        "            nv = normalize_value(v)\n",
        "            nr[nk] = nv\n",
        "        sanitized_results.append(nr)\n",
        "\n",
        "    all_keys = sorted({k for r in sanitized_results for k in r.keys()})\n",
        "    canonical = {}\n",
        "    used = set()\n",
        "    for k in all_keys:\n",
        "        if k in used:\n",
        "            continue\n",
        "        matches = difflib.get_close_matches(k, all_keys, cutoff=0.85)\n",
        "        group = set(matches) | {k}\n",
        "        for m in group:\n",
        "            canonical[m] = k\n",
        "            used.add(m)\n",
        "\n",
        "    merged_results = []\n",
        "    for r in sanitized_results:\n",
        "        mr = {}\n",
        "        for k, v in r.items():\n",
        "            ck = canonical.get(k, k)\n",
        "            if ck not in mr or mr[ck] is None:\n",
        "                mr[ck] = v\n",
        "        if 'document' not in mr and 'document' in r:\n",
        "            mr['document'] = r.get('document')\n",
        "        merged_results.append(mr)\n",
        "\n",
        "    for r in merged_results:\n",
        "        for kk in list(r.keys()):\n",
        "            if r[kk] is None:\n",
        "                r[kk] = np.nan\n",
        "\n",
        "    df = pd.DataFrame(merged_results)\n",
        "\n",
        "    cols = list(df.columns)\n",
        "    if 'document' in cols:\n",
        "        cols = ['document'] + [c for c in cols if c != 'document']\n",
        "        df = df[cols]\n",
        "\n",
        "\n",
        "    output_path = \"../data/output/dynamic_table_final.csv\"\n",
        "    \n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    \n",
        "    df.to_csv(output_path, index=False, na_rep='null')\n",
        "    \n",
        "    print(\"\\n--- Process Complete ---\")\n",
        "    print(f\"DataFrame saved to '{output_path}'  |  shape: {df.shape}\")\n",
        "    print(f\"Total Time: {time.time()-start_time:.2f} s\")\n",
        "    display(df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e95af62a36940c8a998899b52aba8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59deaf6c098246b3be03000f451b5139",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9e4013685e55413ca8ee4c6fef4b2fc0",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "59deaf6c098246b3be03000f451b5139": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b88a01f48924d7393438e0c3129089e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93102a3e79234c278464ac6687b05727",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b80a058c41c242f0b5d5076c97114870",
            "value": "â€‡3/3â€‡[01:52&lt;00:00,â€‡37.22s/it]"
          }
        },
        "90495963d3b740058e315fb78b35439c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93102a3e79234c278464ac6687b05727": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4013685e55413ca8ee4c6fef4b2fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e59ce541fc24e2d94270097128e47bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e95af62a36940c8a998899b52aba8a7",
              "IPY_MODEL_cbecfc9d58c74fdaab62d0ac431ea4b6",
              "IPY_MODEL_8b88a01f48924d7393438e0c3129089e"
            ],
            "layout": "IPY_MODEL_ee05eb469df842a780f0e602e5e482e8"
          }
        },
        "9e9851c3d80e4169a6260e44afaf2706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b80a058c41c242f0b5d5076c97114870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbecfc9d58c74fdaab62d0ac431ea4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90495963d3b740058e315fb78b35439c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e9851c3d80e4169a6260e44afaf2706",
            "value": 3
          }
        },
        "ee05eb469df842a780f0e602e5e482e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
